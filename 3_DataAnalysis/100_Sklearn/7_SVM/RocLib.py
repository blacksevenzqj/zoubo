# -*- coding: utf-8 -*-
"""
Created on Fri Oct 18 12:55:59 2019

@author: seven
"""
import numpy as np
import matplotlib as mpl
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from sklearn.metrics import recall_score

'''
é»˜è®¤æ˜¯ä»¥ ç›®æ ‡å˜é‡ï¼ˆå› å˜é‡Yï¼‰== 1 ä¸ºåŸºå‡†ï¼š
'''


def TP(y_true, y_predict, state=1):
    assert len(y_true) == len(y_predict)
    if state == 1:
        return np.sum((y_true == 1) & (y_predict == 1))
    else:
        return np.sum((y_true == 0) & (y_predict == 0))


def TN(y_true, y_predict, state=1):
    assert len(y_true) == len(y_predict)
    if state == 1:
        return np.sum((y_true == 0) & (y_predict == 0))
    else:
        return np.sum((y_true == 1) & (y_predict == 1))


def FP(y_true, y_predict, state=1):
    assert len(y_true) == len(y_predict)
    if state == 1:
        return np.sum((y_true == 0) & (y_predict == 1))
    else:
        return np.sum((y_true == 1) & (y_predict == 0))


def FN(y_true, y_predict, state=1):
    assert len(y_true) == len(y_predict)
    if state == 1:
        return np.sum((y_true == 1) & (y_predict == 0))
    else:
        return np.sum((y_true == 0) & (y_predict == 1))


# æ··æ·†çŸ©é˜µ
def confusion_matrix_customize(y_true, y_predict, state=1):
    return np.array([
        [TN(y_true, y_predict, state), FP(y_true, y_predict, state)],
        [FN(y_true, y_predict, state), TP(y_true, y_predict, state)],
    ])


# å‡†ç¡®ç‡
def precision_scoreAll_customize(y_true, y_predict, state=1):
    tp = TP(y_true, y_predict, state)
    fp = FP(y_true, y_predict, state)
    tn = TN(y_true, y_predict, state)
    fn = FN(y_true, y_predict, state)
    try:
        return (tp + tn) / (tp + fp + tn + fn)
    except:
        return 0.0


# ç²¾å‡†ç‡
def precision_score_customize(y_true, y_predict, state=1):
    tp = TP(y_true, y_predict, state)
    fp = FP(y_true, y_predict, state)
    try:
        return tp / (tp + fp)
    except:
        return 0.0


# å¬å›ç‡
def recall_score_customize(y_true, y_predict, state=1):
    tp = TP(y_true, y_predict, state)
    fn = FN(y_true, y_predict, state)
    try:
        return tp / (tp + fn)
    except:
        return 0.0


# è°ƒå’Œå¹³å‡å€¼
# F1åˆ†æ•°çš„å…¬å¼ä¸º = 2*æŸ¥å‡†ç‡*æŸ¥å…¨ç‡ / (æŸ¥å‡†ç‡ + æŸ¥å…¨ç‡)
def f1_score_customize(y_true, y_predict, state=1):
    precisionScore = precision_score_customize(y_true, y_predict, state)
    recallScore = recall_score_customize(y_true, y_predict, state)
    try:
        return 2 * precisionScore * recallScore / (precisionScore + recallScore)
    except:
        return 0.0


# TPRï¼šå°±æ˜¯å¬å›ç‡
def TPR(y_true, y_predict, state=1):
    return recall_score_customize(y_true, y_predict, state)


# ç‰¹å¼‚åº¦ï¼š 1-FPR
def SPE(y_true, y_predict, state=1):
    tn = TN(y_true, y_predict, state)
    fp = FP(y_true, y_predict, state)
    try:
        return tn / (tn + fp)
    except:
        return 0.0


# FPRï¼š 1-ç‰¹å¼‚åº¦
def FPR(y_true, y_predict, state=1):
    fp = FP(y_true, y_predict, state)
    tn = TN(y_true, y_predict, state)
    try:
        return fp / (fp + tn)
    except:
        return 0.0


def thresholdSelection(y_true, decision_scores, decision_start, decision_stop, score, score_type=1, state=1):
    thresholds = np.arange(decision_start, decision_stop, 0.1)
    for threshold in thresholds:
        my_predict = np.array(decision_scores >= threshold, dtype='int')
        if score_type == 1:
            if precision_score_customize(y_true, my_predict, state) > score:
                return threshold
            else:
                continue
        elif score_type == 2:
            if recall_score_customize(y_true, my_predict, state) > score:
                return threshold
            else:
                continue
        elif score_type == 3:
            if f1_score_customize(y_true, my_predict, state) > score:
                return threshold
            else:
                continue
        else:
            if FPR(y_true, my_predict, state) < score:
                return threshold
            else:
                continue

    return np.nan


# æ‰‹åŠ¨ç»¼åˆæŒ‡æ ‡ï¼š
def ComprehensiveIndicator(y_true, decision_scores, state=1):
    # 1.1ã€æ‰‹åŠ¨å¾ªç¯ åˆ›å»ºTPRã€FPRï¼š
    precisions = []
    recalls = []
    f1Scores = []
    #    tprs = []
    fprs = []
    thresholds = np.arange(np.min(decision_scores), np.max(decision_scores), 0.1)
    for threshold in thresholds:
        # é‡ç‚¹ï¼šå°† decision_scoresï¼ˆçº¿æ€§å›å½’ğœƒx+bçš„ç»“æœï¼‰ å¤§äºï¼ˆæ­£é¢„æµ‹ï¼‰  å…¶è‡ªèº«åŒºé—´ä¸­çš„æŸä¸€ä¸ªé˜ˆå€¼ çš„ç»“æœ è®¾ç½®ä¸º é¢„æµ‹ç»“æœ
        my_predict = np.array(decision_scores >= threshold, dtype='int')
        precisions.append(precision_score_customize(y_true, my_predict, state))
        recalls.append(recall_score_customize(y_true, my_predict, state))  # TPR
        f1Scores.append(f1_score_customize(y_true, my_predict, state))
        #        tprs.append(TPR(y_true, my_predict, state)) # recalls
        fprs.append(FPR(y_true, my_predict, state))

    # 1.1.1ã€è®¡ç®—KSå€¼åŠå…¶é˜ˆå€¼ï¼šKS=max(TPR-FPR)
    print("æ‰‹åŠ¨è®¡ç®—é•¿åº¦ï¼š", len(thresholds), len(recalls), len(fprs))
    maxKsValue = abs(np.array(recalls) - np.array(fprs)).max()
    maxKsIndex = abs(np.array(recalls) - np.array(fprs)).tolist().index(abs(np.array(recalls) - np.array(fprs)).max())
    maxKsThresholds = thresholds[maxKsIndex]
    recallsValue = recalls[maxKsIndex]
    fprsValue = fprs[maxKsIndex]
    print('max(TPR-FPR) = %.4f, æœ€å¤§é˜ˆå€¼ = %.4f, å¬å›ç‡/TPR = %.4f, FPR = %.4f' % (
    abs(np.array(recalls) - np.array(fprs)).max(), thresholds[maxKsIndex], recalls[maxKsIndex], fprs[maxKsIndex]))
    Ks_PValue = precisions[maxKsIndex]  # KSæœ€å¤§æ—¶ ç²¾å‡†ç‡å€¼
    Ks_f1Value = f1Scores[maxKsIndex]  # KSæœ€å¤§æ—¶ F1åˆ†æ•°å€¼
    print('KSæœ€å¤§é˜ˆå€¼æ—¶ï¼šç²¾å‡†ç‡ = %.4f, F1åˆ†æ•° = %.4f' % (Ks_PValue, Ks_f1Value))

    # 1.1.2ã€è®¡ç®—F1åˆ†æ•°æœ€å¤§å€¼åŠå…¶é˜ˆå€¼ï¼š
    maxF1ScoresValue = max(f1Scores)
    maxF1ScoresIndex = f1Scores.index(max(f1Scores))  # ä»å·¦åˆ°å³ï¼šç¬¬ä¸€ä¸ªå‡ºç°çš„æœ€å¤§æ•°çš„ç´¢å¼•
    maxF1Thresholds = thresholds[maxF1ScoresIndex]
    print('F1æœ€å¤§å€¼ = %.4fï¼Œ' % maxF1ScoresValue, 'æœ€å¤§é˜ˆå€¼ = %.4f' % maxF1Thresholds)
    # 1.1.3ã€è®¡ç®—F1åˆ†æ•°æœ€å¤§å€¼é˜ˆå€¼ ä¸ KSå€¼é˜ˆå€¼ è·ç¦»ï¼š
    diffValue = maxF1Thresholds - maxKsThresholds
    print('F1æœ€å¤§å€¼é˜ˆå€¼ - KSé˜ˆå€¼ = %.4f' % diffValue)

    # é»˜è®¤é˜ˆå€¼
    my_predict_def = np.array(decision_scores >= 0, dtype='int')
    # 1.1.3ã€è®¡ç®—precisionsé»˜è®¤å€¼åŠå…¶é˜ˆå€¼ï¼š
    defPValue = precision_score_customize(y_true, my_predict_def, state)
    print('Precisionsé»˜è®¤å€¼ = %.4fï¼Œ' % defPValue, 'é»˜è®¤é˜ˆå€¼ = 0')

    # 1.1.4ã€è®¡ç®—recalls/TPRé»˜è®¤å€¼åŠå…¶é˜ˆå€¼ï¼š
    defRValue = recall_score_customize(y_true, my_predict_def, state)
    print('Recallsé»˜è®¤å€¼ = %.4fï¼Œ' % defRValue, 'é»˜è®¤é˜ˆå€¼ = 0')

    # 1.1.5ã€è®¡ç®—FPRé»˜è®¤å€¼åŠå…¶é˜ˆå€¼ï¼š
    defFValue = FPR(y_true, my_predict_def, state)
    print('FPRé»˜è®¤å€¼ = %.4fï¼Œ' % defFValue, 'é»˜è®¤é˜ˆå€¼ = 0')

    return thresholds, precisions, recalls, fprs, f1Scores, recallsValue, fprsValue, maxKsThresholds, maxKsValue, maxF1Thresholds, maxF1ScoresValue, diffValue, defPValue, defRValue, defFValue, Ks_PValue, Ks_f1Value


# æ‰‹åŠ¨ç»¼åˆæŒ‡æ ‡å›¾ï¼š
def ComprehensiveIndicatorFigure(y_true, decision_scores, axe, state=1):
    mpl.rcParams['font.sans-serif'] = 'SimHei'
    mpl.rcParams['axes.unicode_minus'] = False

    # 1ã€A1å›¾
    # ä»¥é˜ˆå€¼ä¸ºæ¨ªåæ ‡ï¼Œåˆ†åˆ«ä»¥TPRå’ŒFPRçš„å€¼ä¸ºçºµåæ ‡ï¼Œå°±å¯ä»¥ç”»å‡ºä¸¤ä¸ªæ›²çº¿ï¼Œè¿™å°±æ˜¯K-Sæ›²çº¿
    '''
    åœ¨é˜ˆå€¼ä»æœ€ä½å¤„-85.68ï¼šæ„å‘³ç€ å‡ ä¹æ‰€æœ‰æ ·æœ¬éƒ½è¢«é¢„æµ‹ä¸ºæ­£ä¾‹ï¼Œæ‰€ä»¥ï¼š
    1ã€TPé¢„æµ‹ä¸º1çš„ç›¸å¯¹å¾ˆé«˜ï¼ŒFNæ¼é¢„æµ‹ä¸º1ï¼ˆé”™è¯¯é¢„æµ‹ä¸º0ï¼‰çš„=0ï¼ŒTPR = 1ï¼›
    2ã€FPé”™è¯¯é¢„æµ‹ä¸º1ï¼ˆæ¼é¢„æµ‹ä¸º0ï¼‰çš„ä¹Ÿç›¸å¯¹å¾ˆé«˜ï¼ŒTNé¢„æµ‹ä¸º0=0ï¼ŒFPR = 1ï¼›
    3ã€ä¹Ÿå°±æ˜¯è¯´ åœ¨ é˜ˆå€¼æœ€ä½ç‚¹ çš„æ¨¡å‹ TPR = FPR = 1ï¼ŒKS = max(TPR-FPR) = 0ï¼Œé¢„æµ‹æ²¡æœ‰ä»€ä¹ˆæ„ä¹‰ã€‚
    '''
    thresholds, precisions, recalls, fprs, f1Scores, recallsValue, fprsValue, maxKsThresholds, maxKsValue, maxF1Thresholds, maxF1ScoresValue, diffValue, defPValue, defRValue, defFValue, Ks_PValue, Ks_f1Value = ComprehensiveIndicator(
        y_true, decision_scores, state)
    axe[0].plot(thresholds, precisions, color='blue', label='ç²¾å‡†ç‡')
    axe[0].scatter(0, defPValue, c='#0000FF', s=30, cmap="rainbow")  # è“è‰²
    axe[0].plot(thresholds, recalls, color='black', label='å¬å›ç‡/TPR')
    axe[0].scatter(0, defRValue, c='#000000', s=30, cmap="rainbow")  # é»‘è‰²
    axe[0].plot(thresholds, f1Scores, color='green',
                label='F1é˜ˆå€¼ = %.4fï¼ŒF1 = %.4f' % (maxF1Thresholds, maxF1ScoresValue))
    axe[0].plot(thresholds, fprs, color='pink', label='FPR')
    axe[0].scatter(0, defFValue, c='#FFC0CB', s=30, cmap="rainbow")  # ç²‰è‰²
    axe[0].plot((maxKsThresholds, maxKsThresholds), (recallsValue, fprsValue), c='r', lw=1.5, ls='--', alpha=0.7,
                label='KSé˜ˆå€¼ = %.4fï¼ŒKS = %.4f' % (maxKsThresholds, maxKsValue))
    axe[0].plot((maxKsThresholds, maxF1Thresholds), (maxF1ScoresValue, maxF1ScoresValue), c='purple', lw=1.5, ls='-',
                alpha=0.7, label='(F1-KS)çš„é˜ˆå€¼å·® = %.4f' % diffValue)
    axe[0].scatter(maxKsThresholds, Ks_PValue, c='#0000FF', s=30, cmap="rainbow")  # è“è‰²
    axe[0].scatter(maxKsThresholds, Ks_f1Value, c='#006400', s=30, cmap="rainbow")  # ç»¿è‰²
    axe[0].legend(loc="center left")  # å›¾ä¾‹
    axe[0].set_xlabel('é˜ˆå€¼')  # xè½´æ ‡ç­¾
    axe[0].set_ylabel('ç²¾å‡†ç‡ã€å¬å›ç‡/TPRã€F1åˆ†æ•°ã€FPRã€KS')  # yè½´æ ‡ç­¾
    axe[0].set_title('æ‰‹åŠ¨-é˜ˆå€¼ä¸ç²¾å‡†ç‡ã€å¬å›ç‡/TPRã€F1åˆ†æ•°ã€FPRã€KS=max(TPR-FPR)')  # å›¾å
    axe[0].text(0, defPValue - 0.03, 'é»˜è®¤é˜ˆå€¼0ï¼š%.4f' % defPValue, ha='center', va='bottom')  # fontsize=8
    axe[0].text(0, defRValue + 0.03, 'é»˜è®¤é˜ˆå€¼0ï¼š%.4f' % defRValue, ha='center', va='bottom')
    axe[0].text(0, defFValue - 0.03, 'é»˜è®¤é˜ˆå€¼0ï¼š%.4f' % defFValue, ha='center', va='bottom')
    axe[0].text(maxKsThresholds, recallsValue + 0.01, '%.4f' % recallsValue, ha='center', va='bottom')
    axe[0].text(maxKsThresholds, fprsValue - 0.05, '%.4f' % fprsValue, ha='center', va='bottom')
    axe[0].text(maxKsThresholds, Ks_PValue - 0.03, 'KSé˜ˆå€¼ï¼š%.4f' % Ks_PValue, ha='center', va='bottom')
    axe[0].text(maxKsThresholds, Ks_f1Value - 0.03, 'KSé˜ˆå€¼ï¼š%.4f' % Ks_f1Value, ha='center', va='bottom')

    '''
    ä»ä¸Šé¢ æ‰‹åŠ¨é˜ˆå€¼ ä»ä½åˆ°é«˜ è®¡ç®—å‡ºçš„TPRå’ŒFPRå€¼çš„è¶‹åŠ¿æ˜¯ ä»é«˜åˆ°ä½çš„ï¼›è€Œåœ¨æ›²çº¿å›¾ä¸­TPRå’ŒFPRå€¼è¢«é»˜è®¤è®¾ç½®ä¸º ä»ä½åˆ°é«˜æ˜¾ç¤º
    '''
    axe[1].plot(fprs, recalls, color='purple', label='ROCæ›²çº¿')
    axe[1].plot((0, 1), (0, 1), c='b', lw=1.5, ls='--', alpha=0.7)  # æ¨ªè½´fprs2ï¼š0â†’1èŒƒå›´ï¼›ç«–è½´tprs2ï¼š0â†’1èŒƒå›´
    axe[1].scatter(fprsValue, recallsValue, c=1, s=30, cmap="rainbow")
    axe[1].plot((fprsValue, fprsValue), (recallsValue, fprsValue), c='r', lw=1.5, ls='--', alpha=0.7)
    axe[1].legend(loc="center right")  # å›¾ä¾‹
    axe[1].set_xlabel('FPR')  # xè½´æ ‡ç­¾
    axe[1].set_ylabel('TPR')  # yè½´æ ‡ç­¾
    axe[1].set_title('æ‰‹åŠ¨-ROCæ›²çº¿')  # å›¾å
    axe[1].grid(b=True)
    axe[1].text(fprsValue, recallsValue + 0.01, '%.4f' % recallsValue, ha='center', va='bottom')  # fontsize=8
    axe[1].text(fprsValue, fprsValue - 0.05, '%.4f' % fprsValue, ha='center', va='bottom')
    axe[1].text(fprsValue + 0.05, (fprsValue + recallsValue) / 2, '%.4f' % maxKsValue, ha='center', va='bottom')


# è‡ªåŠ¨
'''
é»˜è®¤æ˜¯ä»¥ ç›®æ ‡å˜é‡ï¼ˆå› å˜é‡Yï¼‰== 1 ä¸ºåŸºå‡†ï¼š
'''


def ComprehensiveIndicatorSkLib(y_true, decision_scores):
    '''
    1ã€roc_curve å‡½æ•°ä½¿ç”¨ decision_scores å’Œ y_log_predict_proba è®¡ç®—å¾—åˆ°çš„ fprs å’Œ tprs ç›¸åŒï¼Œè€Œ é˜ˆå€¼ä¸åŒï¼›y_log_predict_proba è®¡ç®—çš„é˜ˆå€¼ ä¸èƒ½ä½¿ç”¨ã€‚
    2ã€precision_recall_curve å‡½æ•°ä½¿ç”¨ decision_scores å’Œ y_log_predict_proba è®¡ç®—å¾—åˆ°çš„ ç²¾å‡†ç‡ã€å¬å›ç‡ã€F1 ç›¸åŒï¼Œè€Œ é˜ˆå€¼ä¸åŒï¼›y_log_predict_proba è®¡ç®—çš„é˜ˆå€¼ ä¸èƒ½ä½¿ç”¨ã€‚
    '''
    # 1.2ã€è‡ªåŠ¨ åˆ›å»ºTPRã€FPR å¾—åˆ° ROCï¼š
    fprs2, tprs2, thresholds2 = roc_curve(y_true, decision_scores)  # è‡ªåŠ¨-thresholds2 å’Œ æ‰‹åŠ¨-thresholds æ˜¯ä¸å®Œå…¨ç›¸åŒçš„ï¼Œéå¸¸ç±»ä¼¼

    # 1.2.1ã€è‡ªåŠ¨ è®¡ç®—KSå€¼åŠå…¶é˜ˆå€¼ï¼šKS=max(TPR-FPR)
    maxKsValue_auto = abs(np.array(tprs2) - np.array(fprs2)).max()
    maxindex_auto = abs(np.array(tprs2) - np.array(fprs2)).tolist().index(abs(np.array(tprs2) - np.array(fprs2)).max())
    maxKsThresholds_auto = thresholds2[maxindex_auto]
    recallsValue_auto = tprs2[maxindex_auto]
    fprsValue_auto = fprs2[maxindex_auto]
    print('max(TPR-FPR) = %.4f, æœ€å¤§é˜ˆå€¼ = %.4f, å¬å›ç‡/TPR = %.4f, FPR = %.4f' % (
    abs(np.array(tprs2) - np.array(fprs2)).max(), thresholds2[maxindex_auto], tprs2[maxindex_auto],
    fprs2[maxindex_auto]))

    # 1.3ã€è‡ªåŠ¨ åˆ›å»ºAUCé¢ç§¯ï¼šArea Under Curve
    rocAucScore = roc_auc_score(y_true, decision_scores)

    # é»˜è®¤é˜ˆå€¼
    my_predict_def = np.array(decision_scores >= 0, dtype='int')
    # è®¡ç®—recalls/TPRé»˜è®¤å€¼åŠå…¶é˜ˆå€¼ï¼š
    defRValue = recall_score(y_true, my_predict_def)
    print('Recallsé»˜è®¤å€¼ = %.4fï¼Œ' % defRValue, 'é»˜è®¤é˜ˆå€¼ = 0')
    # è®¡ç®—FPRé»˜è®¤å€¼åŠå…¶é˜ˆå€¼ï¼š
    defFValue = FPR(y_true, my_predict_def)
    print('FPRé»˜è®¤å€¼ = %.4fï¼Œ' % defFValue, 'é»˜è®¤é˜ˆå€¼ = 0')

    return thresholds2, tprs2, fprs2, recallsValue_auto, fprsValue_auto, maxKsThresholds_auto, maxKsValue_auto, rocAucScore, defRValue, defFValue


# è‡ªåŠ¨å›¾
def ComprehensiveIndicatorSkLibFigure(y_true, decision_scores, axe):
    mpl.rcParams['font.sans-serif'] = 'SimHei'
    mpl.rcParams['axes.unicode_minus'] = False

    thresholds2, tprs2, fprs2, recallsValue_auto, fprsValue_auto, maxKsThresholds_auto, maxKsValue_auto, rocAucScore, defRValue, defFValue = ComprehensiveIndicatorSkLib(
        y_true, decision_scores)
    axe[0].plot(thresholds2, tprs2, color='black', label='å¬å›ç‡/TPR')
    axe[0].plot(thresholds2, fprs2, color='pink', label='FPR')
    axe[0].plot((maxKsThresholds_auto, maxKsThresholds_auto), (recallsValue_auto, fprsValue_auto), c='r', lw=1.5,
                ls='--', alpha=0.7, label='KS = %.4fï¼ŒKSé˜ˆå€¼ = %.4f' % (maxKsValue_auto, maxKsThresholds_auto))
    axe[0].scatter(0, defRValue, c='#000000', s=30, cmap="rainbow")  # é»‘è‰²
    axe[0].scatter(0, defFValue, c='#FFC0CB', s=30, cmap="rainbow")  # ç²‰è‰²
    axe[0].legend(loc='lower left')  # å›¾ä¾‹
    axe[0].set_xlabel('é˜ˆå€¼')  # xè½´æ ‡ç­¾
    axe[0].set_ylabel('å¬å›ç‡/TPRã€FPRã€KS')  # yè½´æ ‡ç­¾
    axe[0].set_title('è‡ªåŠ¨-é˜ˆå€¼ä¸å¬å›ç‡/TPRã€FPRã€KS=max(TPR-FPR)')  # å›¾å
    axe[0].text(0, defRValue + 0.03, 'é»˜è®¤é˜ˆå€¼0ï¼š%.4f' % defRValue, ha='center', va='bottom')
    axe[0].text(0, defFValue - 0.03, 'é»˜è®¤é˜ˆå€¼0ï¼š%.4f' % defFValue, ha='center', va='bottom')
    axe[0].text(maxKsThresholds_auto, recallsValue_auto + 0.01, '%.4f' % recallsValue_auto, ha='center',
                va='bottom')  # fontsize=8
    axe[0].text(maxKsThresholds_auto, fprsValue_auto - 0.05, '%.4f' % fprsValue_auto, ha='center', va='bottom')

    axe[1].plot(fprs2, tprs2, color='purple', label='AUC=%.3f' % rocAucScore)
    axe[1].plot((0, 1), (0, 1), c='b', lw=1.5, ls='--', alpha=0.7)  # æ¨ªè½´fprs2ï¼š0â†’1èŒƒå›´ï¼›ç«–è½´tprs2ï¼š0â†’1èŒƒå›´
    axe[1].scatter(fprsValue_auto, recallsValue_auto, c=1, s=30, cmap="rainbow")
    axe[1].plot((fprsValue_auto, fprsValue_auto), (recallsValue_auto, fprsValue_auto), c='r', lw=1.5, ls='--',
                alpha=0.7)
    axe[1].set_xlabel('FPR')  # xè½´æ ‡ç­¾
    axe[1].set_ylabel('TPR')  # yè½´æ ‡ç­¾
    axe[1].grid(b=True)
    axe[1].legend(loc='lower right', fancybox=True, framealpha=0.8, fontsize=14)
    axe[1].set_title('è‡ªåŠ¨-ROCæ›²çº¿å’ŒAUCå€¼')  # fontsize=17
    axe[1].text(fprsValue_auto, recallsValue_auto + 0.01, '%.4f' % recallsValue_auto, ha='center',
                va='bottom')  # fontsize=8
    axe[1].text(fprsValue_auto, fprsValue_auto - 0.05, '%.4f' % fprsValue_auto, ha='center', va='bottom')
    axe[1].text(fprsValue_auto + 0.05, (fprsValue_auto + recallsValue_auto) / 2, '%.4f' % maxKsValue_auto, ha='center',
                va='bottom')


# è®­ç»ƒé›† ä¸ æµ‹è¯•é›† ROCæ¯”è¾ƒ
def comparedRoc(y_true_train, decision_scores_train, y_true_test, decision_scores_test, axe):
    mpl.rcParams['font.sans-serif'] = 'SimHei'
    mpl.rcParams['axes.unicode_minus'] = False

    fpr_train, tpr_train, th_train = roc_curve(y_true_train, decision_scores_train)
    rocAucScore_train = roc_auc_score(y_true_train, decision_scores_train)

    fpr_test, tpr_test, th_test = roc_curve(y_true_test, decision_scores_test)
    rocAucScore_test = roc_auc_score(y_true_test, decision_scores_test)

    axe.plot(fpr_train, tpr_train, color='red', label='AUC_Train = %.3f' % rocAucScore_train)
    axe.plot(fpr_test, tpr_test, color='blue', label='AUC_Test = %.3f' % rocAucScore_test)
    axe.plot((0, 1), (0, 1), c='b', lw=1.5, ls='--', alpha=0.7)  # æ¨ªè½´fprs2ï¼š0â†’1èŒƒå›´ï¼›ç«–è½´tprs2ï¼š0â†’1èŒƒå›´
    axe.set_xlabel('FPR')  # xè½´æ ‡ç­¾
    axe.set_ylabel('TPR')  # yè½´æ ‡ç­¾
    axe.legend(loc='lower right', fancybox=True, framealpha=0.8, fontsize=14)
    axe.set_title('è‡ªåŠ¨-ROCæ›²çº¿Trainä¸Testå¯¹æ¯”')




