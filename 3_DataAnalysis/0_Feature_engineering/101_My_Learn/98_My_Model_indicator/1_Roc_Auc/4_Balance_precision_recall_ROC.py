import numpy as np
from sklearn import datasets
import matplotlib as mpl
import matplotlib.pyplot as plt


digits = datasets.load_digits()
x = digits.data
y = digits.target.copy()
print('xçš„é•¿åº¦%i' % len(x), 'yçš„é•¿åº¦%i:' % len(y))

# ä½¿æ•°æ®é›†çš„æ ·æœ¬æ¯”ä¾‹çš„ä¸¥é‡åæ–œï¼Œå˜ä¸º2åˆ†ç±»
y[digits.target == 9] = 1
y[digits.target != 9] = 0

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=666)

from sklearn.linear_model import LogisticRegression

# æ²¡æœ‰ä½¿ç”¨äº¤å‰éªŒè¯é€‰æ­£åˆ™é¡¹å€¼ï¼ˆroc_aucè¯„åˆ†æ ‡å‡†ï¼‰  æˆ–  ç›´æ¥ä½¿ç”¨ LogisticRegressionCV ç±»è‡ªå¸¦çš„äº¤å‰éªŒè¯åŠŸèƒ½
log_reg = LogisticRegression()
log_reg.fit(x_train, y_train) # æ¨¡å‹è®­ç»ƒæ—¶ï¼šæ˜¯ä¸ç”¨é˜ˆå€¼çš„ï¼Œå…·ä½“ç»†çœ‹æŸå¤±å‡½æ•°åŠå…¶æ±‚åå¯¼çš„è¿‡ç¨‹ã€‚

score = log_reg.score(x_test, y_test) # ç›´æ¥æ±‚ å‡†ç¡®ç‡
# print(score)

y_log_predict = log_reg.predict(x_test) # æ±‚ é¢„æµ‹å€¼

y_log_predict_proba = log_reg.predict_proba(x_test)[:,1] # æ±‚ é¢„æµ‹å€¼ æ¦‚ç‡
y_log_predict_proba_predict = np.array(y_log_predict_proba >= 0.5, dtype='int')
# print(len(y_test), np.sum(y_log_predict == y_log_predict_proba_predict)) # ä¸¤è€…ç›¸åŒï¼Œå¯è§ é»˜è®¤æ¦‚ç‡ä¸º 0.5

decision_scores = log_reg.decision_function(x_test) # ç†è§£ä¸ºï¼šçº¿æ€§å›å½’ ğœƒx+b çš„ç»“æœ


'''
é»˜è®¤æ˜¯ä»¥ ç›®æ ‡å˜é‡ï¼ˆå› å˜é‡Yï¼‰== 1 ä¸ºåŸºå‡†ï¼š
'''
def TP(y_true, y_predict):
    assert len(y_true) == len(y_predict)
    return np.sum((y_true == 1) & (y_predict == 1))

# predictTP = TP(y_test, y_log_predict)
# print(predictTP)

def TN(y_true, y_predict):
    assert len(y_true) == len(y_predict)
    return np.sum((y_true == 0) & (y_predict == 0))

# predictTN = TN(y_test, y_log_predict)
# print(predictTN)

def FP(y_true, y_predict):
    assert len(y_true) == len(y_predict)
    return np.sum((y_true == 0) & (y_predict == 1))

# predictFP = FP(y_test, y_log_predict)
# print(predictFP)

def FN(y_true, y_predict):
    assert len(y_true) == len(y_predict)
    return np.sum((y_true == 1) & (y_predict == 0))

# predictFN = FN(y_test, y_log_predict)
# print(predictFN)

# æ··æ·†çŸ©é˜µ
def confusion_matrix(y_true, y_predict):
    return np.array([
        [TN(y_true, y_predict), FP(y_true, y_predict)],
        [FN(y_true, y_predict), TP(y_true, y_predict)],
    ])

# matrix = confusion_matrix(y_test, y_log_predict)
# print(matrix)

# å‡†ç¡®ç‡
def precision_scoreAll(y_true, y_predict):
    tp = TP(y_true, y_predict)
    fp = FP(y_true, y_predict)
    tn = TN(y_true, y_predict)
    fn = FN(y_true, y_predict)
    try:
        return (tp + tn) / (tp + fp + tn + fn)
    except:
        return 0.0

# precisionScoreAll = precision_scoreAll(y_test, y_log_predict)
# print(precisionScoreAll)

# ç²¾å‡†ç‡
def precision_score(y_true, y_predict):
    tp = TP(y_true, y_predict)
    fp = FP(y_true, y_predict)
    try:
        return tp / (tp + fp)
    except:
        return 0.0

# precisionScore = precision_score(y_test, y_log_predict)
# print(precisionScore)

# å¬å›ç‡
def recall_score(y_true, y_predict):
    tp = TP(y_true, y_predict)
    fn = FN(y_true, y_predict)
    try:
        return tp / (tp + fn)
    except:
        return 0.0

# recallScore = recall_score(y_test, y_log_predict)
# print(recallScore)

# è°ƒå’Œå¹³å‡å€¼
# F1åˆ†æ•°çš„å…¬å¼ä¸º = 2*æŸ¥å‡†ç‡*æŸ¥å…¨ç‡ / (æŸ¥å‡†ç‡ + æŸ¥å…¨ç‡)
def f1_score_my(precisionScore, recallScore):
    try:
        return 2 * precisionScore * recallScore / (precisionScore + recallScore)
    except:
        return 0.0

# f1Score = f1_score_my(precisionScore, recallScore)
# print(f1Score)

# TPRï¼šå°±æ˜¯å¬å›ç‡
def TPR(y_true, y_predict):
    return recall_score(y_true, y_predict)

# tprScore = TPR(y_test, y_log_predict)
# print(tprScore)

# FPRï¼š
def FPR(y_true, y_predict):
    fp = FP(y_true, y_predict)
    tn = TN(y_true, y_predict)
    try:
        return fp / (fp + tn)
    except:
        return 0.0

# fprScore = FPR(y_test, y_log_predict)
# print(fprScore)


print("=============================================================================================")


'''
é»˜è®¤æ˜¯ä»¥ ç›®æ ‡å˜é‡ï¼ˆå› å˜é‡Yï¼‰== 1 ä¸ºåŸºå‡†ï¼š
'''
# æ··æ·†çŸ©é˜µ
from sklearn.metrics import confusion_matrix
confusionMatrix = confusion_matrix(y_test, y_log_predict)
# print(confusionMatrix)

# å‡†ç¡®ç‡
from sklearn.metrics import accuracy_score
accuracyScore = accuracy_score(y_test, y_log_predict)
# print(accuracyScore)

# ç²¾å‡†ç‡
from sklearn.metrics import precision_score
precisionScore = precision_score(y_test, y_log_predict)
# print(precisionScore)

# å¬å›ç‡
from sklearn.metrics import recall_score
recallScore = recall_score(y_test, y_log_predict)
# print(recallScore)

# F1åˆ†æ•°
from sklearn.metrics import f1_score
f1Score = f1_score(y_test, y_log_predict)
# print(f1Score)

# å¤šåˆ†ç±»ç»¼åˆæŒ‡æ ‡ï¼šåªæœ‰è¿™ä¸ªæŒ‡æ ‡èƒ½è®¡ç®—å¤šåˆ†ç±»ï¼Œä»¥ä¸Šçš„éƒ½æ˜¯è®¡ç®—äºŒåˆ†ç±»çš„ï¼ˆä»¥æ¯ä¸ªç±»åˆ«ä¸ºåŸºå‡†ï¼Œåˆ†åˆ«è®¡ç®— æ¯ä¸ªç±»åˆ«å„è‡ªçš„ ç²¾å‡†ç‡ã€å¬å›ç‡ã€F1 ç­‰æŒ‡æ ‡ï¼‰
from sklearn.metrics import classification_report
classificationReport = classification_report(y_test, y_log_predict)
# print(classificationReport)


print("=============================================================================================")


# matplotlib å›¾è¡¨ä¸­æ–‡æ˜¾ç¤º
mpl.rcParams['font.sans-serif'] = 'SimHei'
mpl.rcParams['axes.unicode_minus'] = False

# 1.1ã€æ‰‹åŠ¨å¾ªç¯ åˆ›å»ºTPRã€FPRï¼š
precisions = []
recalls = []
f1Scores = []
tprs = []
fprs = []
thresholds = np.arange(np.min(decision_scores), np.max(decision_scores), 0.1)
for threshold in thresholds:
    # é‡ç‚¹ï¼šå°† decision_scoresï¼ˆçº¿æ€§å›å½’ğœƒx+bçš„ç»“æœï¼‰ å¤§äºï¼ˆæ­£é¢„æµ‹ï¼‰  å…¶è‡ªèº«åŒºé—´ä¸­çš„æŸä¸€ä¸ªé˜ˆå€¼ çš„ç»“æœ è®¾ç½®ä¸º é¢„æµ‹ç»“æœ
    my_predict = np.array(decision_scores >= threshold, dtype='int')
    precisions.append(precision_score(y_test, my_predict))
    recalls.append(recall_score(y_test, my_predict)) # TPR
    f1Scores.append(f1_score(y_test, my_predict))
    tprs.append(TPR(y_test, my_predict)) # recalls
    fprs.append(FPR(y_test, my_predict))
    # print(confusion_matrix(y_test, my_predict))

# print("é˜ˆå€¼ï¼š", thresholds[0:10], 'ç»´åº¦ï¼š', len(thresholds)) # 1056
# print("å‡†ç¡®ç‡ï¼š", precisions[0:10], 'ç»´åº¦ï¼š', len(precisions)) # 1056
# print("å¬å›ç‡ï¼š", recalls[0:10], 'ç»´åº¦ï¼š', len(recalls)) # 1056
# print("F1åˆ†æ•°ï¼š", f1Scores[0:10], 'ç»´åº¦ï¼š', len(f1Scores)) # 1056
# print("TPRï¼š", tprs[0:10], 'ç»´åº¦ï¼š', len(tprs))
# print("FPRï¼š", fprs[0:10], 'ç»´åº¦ï¼š', len(fprs))

# 1.1.1ã€è®¡ç®—KSå€¼åŠå…¶é˜ˆå€¼ï¼šKS=max(TPR-FPR)
print("æ‰‹åŠ¨è®¡ç®—é•¿åº¦ï¼š", len(thresholds), len(recalls), len(fprs))
tempValue = 0.00
maxKsValue = 0.00
maxKsThresholds = 0.00
recallsValue = 0.00
fprsValue = 0.00
for i in np.arange(len(thresholds)):
    tempValue = abs(recalls[i] - fprs[i])
    if tempValue > maxKsValue:
        maxKsValue = tempValue
        maxKsThresholds = thresholds[i]
        recallsValue = recalls[i]
        fprsValue = fprs[i]
print('max(TPR-FPR) = %.6fï¼Œ' % maxKsValue, 'æœ€å¤§é˜ˆå€¼ = %.6f' % maxKsThresholds)
print('max(TPR-FPR) = %.6f' % abs(np.array(recalls) - np.array(fprs)).max())

# 1.1.2ã€è®¡ç®—F1åˆ†æ•°æœ€å¤§å€¼åŠå…¶é˜ˆå€¼ï¼š
maxF1ScoresValue = max(f1Scores)
maxF1ScoresIndex = f1Scores.index(max(f1Scores)) # ä»å·¦åˆ°å³ï¼šç¬¬ä¸€ä¸ªå‡ºç°çš„æœ€å¤§æ•°çš„ç´¢å¼•
maxF1Thresholds = thresholds[maxF1ScoresIndex]
print('F1æœ€å¤§å€¼ = %.6fï¼Œ' % maxF1ScoresValue, 'æœ€å¤§é˜ˆå€¼ = %.6f' % maxF1Thresholds)
# 1.1.3ã€è®¡ç®—F1åˆ†æ•°æœ€å¤§å€¼é˜ˆå€¼ ä¸ KSå€¼é˜ˆå€¼ è·ç¦»ï¼š
diffValue = maxF1Thresholds - maxKsThresholds
print('F1æœ€å¤§å€¼é˜ˆå€¼ - KSé˜ˆå€¼ = %.6f' % diffValue)


print("-------------------------------------------------------------------------------------------------------")


'''
1ã€roc_curve å‡½æ•°ä½¿ç”¨ decision_scores å’Œ y_log_predict_proba è®¡ç®—å¾—åˆ°çš„ fprs å’Œ tprs ç›¸åŒï¼Œè€Œ é˜ˆå€¼ä¸åŒï¼›y_log_predict_proba è®¡ç®—çš„é˜ˆå€¼ ä¸èƒ½ä½¿ç”¨ã€‚  
2ã€precision_recall_curve å‡½æ•°ä½¿ç”¨ decision_scores å’Œ y_log_predict_proba è®¡ç®—å¾—åˆ°çš„ ç²¾å‡†ç‡ã€å¬å›ç‡ã€F1 ç›¸åŒï¼Œè€Œ é˜ˆå€¼ä¸åŒï¼›y_log_predict_proba è®¡ç®—çš„é˜ˆå€¼ ä¸èƒ½ä½¿ç”¨ã€‚  
'''
# 1.2ã€è‡ªåŠ¨ åˆ›å»ºTPRã€FPR å¾—åˆ° ROCï¼š
from sklearn.metrics import roc_curve
fprs2, tprs2, thresholds2 = roc_curve(y_test, decision_scores) # è‡ªåŠ¨-thresholds2 å’Œ æ‰‹åŠ¨-thresholds æ˜¯ä¸å®Œå…¨ç›¸åŒçš„ï¼Œéå¸¸ç±»ä¼¼
fprs3, tprs3, thresholds3 = roc_curve(y_test, y_log_predict_proba) # è‡ªåŠ¨-thresholds2 å’Œ è‡ªåŠ¨-thresholds3 å®Œå…¨ä¸åŒï¼Œè‡ªåŠ¨-thresholds3 ä¸èƒ½ç”¨ã€‚
# ä¸¤ç§æ–¹å¼ï¼šTPRã€FPRç›¸åŒï¼Œé˜ˆå€¼ä¸ç›¸åŒ
print("è‡ªåŠ¨è®¡ç®—é•¿åº¦1ï¼š", len(thresholds2), len(tprs2), len(fprs2))
print("è‡ªåŠ¨è®¡ç®—é•¿åº¦2ï¼š", len(thresholds3), len(tprs3), len(fprs3))
print("å¯¹æ¯”1ï¼šTPRã€FPRç›¸åŒï¼Œé˜ˆå€¼ä¸ç›¸åŒï¼š", len(fprs2)==len(fprs3), sum(fprs2 == fprs3), len(tprs2)==len(tprs3), sum(tprs2 == tprs3), len(thresholds2)==len(thresholds3), sum(thresholds2 == thresholds3))
# TPRã€FPRç›¸åŒï¼Œè€Œé˜ˆå€¼ä¸ç›¸åŒï¼Œæ‰€ä»¥ è‡ªåŠ¨-thresholds3 ä¸èƒ½ç”¨ï¼Œæœ‰é—®é¢˜ã€‚
print("å¯¹æ¯”1ï¼šé˜ˆå€¼æ¯”è¾ƒï¼š", np.min(thresholds2), np.max(thresholds2), np.min(thresholds3), np.max(thresholds3))

# 1.2.1ã€è‡ªåŠ¨ è®¡ç®—KSå€¼åŠå…¶é˜ˆå€¼ï¼šKS=max(TPR-FPR)
tempValue_auto = 0.00
maxKsValue_auto = 0.00
maxKsThresholds_auto = 0.00
recallsValue_auto = 0.00
fprsValue_auto = 0.00
for i in np.arange(len(thresholds2)):
    tempValue_auto = abs(tprs2[i] - fprs2[i])
    if tempValue_auto > maxKsValue_auto:
        maxKsValue_auto = tempValue_auto
        maxKsThresholds_auto = thresholds2[i]
        recallsValue_auto = tprs2[i]
        fprsValue_auto = fprs2[i]
print('max(TPR-FPR) = %.6fï¼Œ' % maxKsValue_auto, 'æœ€å¤§é˜ˆå€¼ = %.6f' % maxKsThresholds_auto)
print('max(TPR-FPR) = %.6f' % abs(np.array(tprs2) - np.array(fprs2)).max())

# 1.3ã€è‡ªåŠ¨ åˆ›å»ºAUCé¢ç§¯ï¼šArea Under Curve
from sklearn.metrics import roc_auc_score
rocAucScore = roc_auc_score(y_test, decision_scores)
rocAucScore3 = roc_auc_score(y_test, y_log_predict_proba)
# print(rocAucScore, rocAucScore3) # ä¸¤ç§æ–¹å¼ç»“æœç›¸åŒ

# 1.4ã€è‡ªåŠ¨ åˆ›å»º å¬å›ç‡/TPRã€F1åˆ†æ•°ï¼ˆæœ¬æ„æ˜¯ç›´æ¥åˆ›å»ºP-Ræ›²çº¿ï¼Œå¯ä»¥ç”¨ä¸Šé¢åˆ†å¼€çš„å…¬å¼ä»£æ›¿çš„ï¼Œéƒ½æµ‹è¯•ä½¿ç”¨ä¸‹ï¼‰
from sklearn.metrics import precision_recall_curve # P-Ræ›²çº¿
precisions4, recalls4, thresholds4 = precision_recall_curve(y_test, decision_scores)
f1Scores4 = f1_score_my(precisions4[:-1], recalls4[:-1])
print("è‡ªåŠ¨è®¡ç®—é•¿åº¦3ï¼š", len(precisions4), len(recalls4), len(thresholds4), len(f1Scores4))
# æ³¨æ„ï¼šprecision_recall_curve å’Œ roc_curve ä¸¤å‡½æ•°ä½¿ç”¨ decision_scores è®¡ç®—çš„ é˜ˆå€¼åŒºé—´èŒƒå›´éå¸¸ä¸ç›¸åŒï¼Œæ‰€ä»¥ä¸èƒ½åˆå¹¶ä½¿ç”¨æŒ‡æ ‡ã€‚é™¤éåƒ æ‰‹åŠ¨-1.1ã€1.1.1ã€1.1.2ã€1.1.3 é‚£æ ·å…¨éƒ¨é‡æ–°è®¡ç®—ã€‚

precisions5, recalls5, thresholds5 = precision_recall_curve(y_test, y_log_predict_proba)# è‡ªåŠ¨-thresholds4 å’Œ è‡ªåŠ¨-thresholds5 å®Œå…¨ä¸åŒï¼Œè‡ªåŠ¨-thresholds5 ä¸èƒ½ç”¨ã€‚
f1Scores5 = f1_score_my(precisions5[:-1], recalls5[:-1])
print("è‡ªåŠ¨è®¡ç®—é•¿åº¦4ï¼š", len(precisions5), len(recalls5), len(thresholds5), len(f1Scores4))
print("å¯¹æ¯”2ï¼šç²¾å‡†ç‡ã€å¬å›ç‡ã€F1ç›¸åŒï¼Œé˜ˆå€¼ä¸ç›¸åŒï¼š", len(precisions4)==len(precisions5), sum(precisions4 == precisions5), len(recalls4)==len(recalls5), sum(recalls4 == recalls5), len(f1Scores4)==len(f1Scores5), sum(f1Scores4 == f1Scores5), len(thresholds4)==len(thresholds5), sum(thresholds4 == thresholds5))
# ç²¾å‡†ç‡ã€å¬å›ç‡ã€F1ç›¸åŒï¼Œè€Œé˜ˆå€¼ä¸ç›¸åŒï¼Œæ‰€ä»¥ è‡ªåŠ¨-thresholds5 ä¸èƒ½ç”¨ï¼Œæœ‰é—®é¢˜ã€‚
print("å¯¹æ¯”2ï¼šé˜ˆå€¼æ¯”è¾ƒï¼š", np.min(thresholds4), np.max(thresholds4), np.min(thresholds5), np.max(thresholds5))



fig = plt.figure(figsize = (24,12))
# 1ã€A1å›¾
# ä»¥é˜ˆå€¼ä¸ºæ¨ªåæ ‡ï¼Œåˆ†åˆ«ä»¥TPRå’ŒFPRçš„å€¼ä¸ºçºµåæ ‡ï¼Œå°±å¯ä»¥ç”»å‡ºä¸¤ä¸ªæ›²çº¿ï¼Œè¿™å°±æ˜¯K-Sæ›²çº¿
'''
åœ¨é˜ˆå€¼ä»æœ€ä½å¤„-85.68ï¼šæ„å‘³ç€ å‡ ä¹æ‰€æœ‰æ ·æœ¬éƒ½è¢«é¢„æµ‹ä¸ºæ­£ä¾‹ï¼Œæ‰€ä»¥ï¼š
1ã€TPé¢„æµ‹ä¸º1çš„ç›¸å¯¹å¾ˆé«˜ï¼ŒFNæ¼é¢„æµ‹ä¸º1ï¼ˆé”™è¯¯é¢„æµ‹ä¸º0ï¼‰çš„=0ï¼ŒTPR = 1ï¼›
2ã€FPé”™è¯¯é¢„æµ‹ä¸º1ï¼ˆæ¼é¢„æµ‹ä¸º0ï¼‰çš„ä¹Ÿç›¸å¯¹å¾ˆé«˜ï¼ŒTNé¢„æµ‹ä¸º0=0ï¼ŒFPR = 1ï¼›
3ã€ä¹Ÿå°±æ˜¯è¯´ åœ¨ é˜ˆå€¼æœ€ä½ç‚¹ çš„æ¨¡å‹ TPR = FPR = 1ï¼ŒKS = max(TPR-FPR) = 0ï¼Œé¢„æµ‹æ²¡æœ‰ä»€ä¹ˆæ„ä¹‰ã€‚
'''
ax1 = fig.add_subplot(2,2,1)
plt.plot(thresholds, precisions, color = 'blue', label='ç²¾å‡†ç‡')
plt.plot(thresholds, recalls, color='black', label='å¬å›ç‡/TPR')
plt.plot(thresholds, f1Scores, color='green', label='F1åˆ†æ•°é˜ˆå€¼ = %.6f' % maxF1Thresholds)
plt.plot(thresholds, fprs, color='pink', label='FPR')
plt.plot((maxKsThresholds,maxKsThresholds), (recallsValue,fprsValue), c='r', lw=1.5, ls='--', alpha=0.7, label='KSé˜ˆå€¼ = %.6f' % maxKsThresholds)
plt.plot((maxKsThresholds,maxF1Thresholds), (maxF1ScoresValue,maxF1ScoresValue), c='purple', lw=1.5, ls='-', alpha=0.7, label='(F1-KS)çš„é˜ˆå€¼å·® = %.4f' % diffValue)
plt.legend()  # å›¾ä¾‹
plt.xlabel('é˜ˆå€¼')  # xè½´æ ‡ç­¾
plt.ylabel('ç²¾å‡†ç‡ã€å¬å›ç‡/TPRã€F1åˆ†æ•°ã€FPRã€KS') # yè½´æ ‡ç­¾
plt.title('æ‰‹åŠ¨-é˜ˆå€¼ä¸ç²¾å‡†ç‡ã€å¬å›ç‡/TPRã€F1åˆ†æ•°ã€FPRã€KS=max(TPR-FPR)')  # å›¾å


# 2ã€A2å›¾
ax2 = fig.add_subplot(2,2,2)
'''
ä»ä¸Šé¢ æ‰‹åŠ¨é˜ˆå€¼ ä»ä½åˆ°é«˜ è®¡ç®—å‡ºçš„TPRå’ŒFPRå€¼çš„è¶‹åŠ¿æ˜¯ ä»é«˜åˆ°ä½çš„ï¼›è€Œåœ¨æ›²çº¿å›¾ä¸­TPRå’ŒFPRå€¼è¢«é»˜è®¤è®¾ç½®ä¸º ä»ä½åˆ°é«˜æ˜¾ç¤º
'''
plt.plot(fprs, tprs, color='purple', label='ROCæ›²çº¿')
plt.legend()  # å›¾ä¾‹
plt.xlabel('FPR')  # xè½´æ ‡ç­¾
plt.ylabel('TPR') # yè½´æ ‡ç­¾
plt.title('æ‰‹åŠ¨-ROCæ›²çº¿')  # å›¾å



# 3ã€B1å›¾
ax3 = fig.add_subplot(2,2,3)
# æ³¨æ„ï¼šprecision_recall_curve å’Œ roc_curve ä¸¤å‡½æ•°ä½¿ç”¨ decision_scores è®¡ç®—çš„ é˜ˆå€¼åŒºé—´èŒƒå›´éå¸¸ä¸ç›¸åŒï¼Œæ‰€ä»¥ä¸èƒ½åˆå¹¶ä½¿ç”¨æŒ‡æ ‡ã€‚é™¤éåƒ æ‰‹åŠ¨-1.1ã€1.1.1ã€1.1.2ã€1.1.3 é‚£æ ·å…¨éƒ¨é‡æ–°è®¡ç®—ã€‚
# plt.plot(thresholds4, precisions4[:-1], color = 'blue', label='ç²¾å‡†ç‡') # thresholds4 å’Œ thresholds5 çš„ ç²¾å‡†ç‡ã€å¬å›ç‡ã€F1ç›¸åŒï¼Œè€Œé˜ˆå€¼ä¸ç›¸åŒï¼Œæ‰€ä»¥ è‡ªåŠ¨-thresholds5 ä¸èƒ½ç”¨ï¼Œæœ‰é—®é¢˜ã€‚
# plt.plot(thresholds4, recalls4[:-1], color='black', label='å¬å›ç‡')
# plt.plot(thresholds4, f1Scores4, color='green', label='F1åˆ†æ•°')
# plt.legend()  # å›¾ä¾‹
# plt.xlabel('é˜ˆå€¼')  # xè½´æ ‡ç­¾
# plt.ylabel('ç²¾å‡†ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°') # yè½´æ ‡ç­¾
# plt.title('è‡ªåŠ¨-é˜ˆå€¼ä¸ç²¾å‡†ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°')  # å›¾å

plt.plot(thresholds2, tprs2, color='black', label='å¬å›ç‡/TPR') # thresholds2 å’Œ thresholds3 çš„ TPRã€FPRç›¸åŒï¼Œè€Œé˜ˆå€¼ä¸ç›¸åŒï¼Œæ‰€ä»¥ è‡ªåŠ¨-thresholds3 ä¸èƒ½ç”¨ï¼Œæœ‰é—®é¢˜ã€‚
plt.plot(thresholds2, fprs2, color='pink', label='FPR')
plt.plot((maxKsThresholds_auto,maxKsThresholds_auto), (recallsValue_auto,fprsValue_auto), c='r', lw=1.5, ls='--', alpha=0.7, label='KSé˜ˆå€¼ = %.6f' % maxKsThresholds_auto)
plt.legend()  # å›¾ä¾‹
plt.xlabel('é˜ˆå€¼')  # xè½´æ ‡ç­¾
plt.ylabel('å¬å›ç‡/TPRã€FPRã€KS') # yè½´æ ‡ç­¾
plt.title('è‡ªåŠ¨-é˜ˆå€¼ä¸å¬å›ç‡/TPRã€FPRã€KS=max(TPR-FPR)')  # å›¾å


# 4ã€B2å›¾
ax4 = fig.add_subplot(2,2,4)
plt.plot(fprs2, tprs2, color='purple', label='AUC=%.3f' % rocAucScore)
plt.plot((0, 1), (0, 1), c='b', lw=1.5, ls='--', alpha=0.7) # æ¨ªè½´fprs2ï¼š0â†’1èŒƒå›´ï¼›ç«–è½´tprs2ï¼š0â†’1èŒƒå›´
plt.xlabel('FPR')  # xè½´æ ‡ç­¾
plt.ylabel('TPR') # yè½´æ ‡ç­¾
plt.grid(b=True)
plt.legend(loc='lower right', fancybox=True, framealpha=0.8, fontsize=14)
plt.title('è‡ªåŠ¨-ROCæ›²çº¿å’ŒAUCå€¼', fontsize=17)


plt.show()